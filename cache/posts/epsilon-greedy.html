
<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">Background</h2>
<div class="outline-text-2" id="text-1">
<p>
This is an implementation of the Epsilon Greedy algorithm to find solutions for the multi-arm-bandit problem.
</p>
</div>
</div>
<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">Imports</h2>
<div class="outline-text-2" id="text-2">
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="c1"># python</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">jit</span>
<span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">Find First</h2>
<div class="outline-text-2" id="text-3">
<p>
This is a helper function to find the first matching item in an array-like collection.
</p>

/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">find_first</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">vector</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;find the first item in the vector</span>

<span class="sd">    Args:</span>
<span class="sd">     item: thing to match</span>
<span class="sd">     vector: thing to search</span>

<span class="sd">    Returns:</span>
<span class="sd">     value: index of first matching item, -1 if not found</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vector</span><span class="p">)):</span>
	<span class="k">if</span> <span class="n">item</span> <span class="o">==</span> <span class="n">vector</span><span class="p">[</span><span class="n">index</span><span class="p">]:</span>
	    <span class="k">return</span> <span class="n">index</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span>
</pre></div>
</div>
</div>

<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4">Epsilon Greedy</h2>
<div class="outline-text-2" id="text-4">
<p>
The <i>epsilon-greedy</i> algorithm tries to solve the exploitation-exploration dilemna by exploring a fraction of the time (set by <i>epsilon</i>) and using the best solution found so far the rest of the time. This implementation is based on the one in Bandit Algorithms for Website Optimization<sup><a id="fnr.1" name="fnr.1" class="footref" href="#fn.1">1</a></sup>.
</p>

/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="o">&lt;&lt;</span><span class="n">imports</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">find</span><span class="o">-</span><span class="n">first</span><span class="o">&gt;&gt;</span>
<span class="k">class</span> <span class="nc">EpsilonGreedy</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The Epsilon Greedy Algorithm</span>

<span class="sd">    Args:</span>
<span class="sd">     epsilon (float): fraction of the time to explore</span>
<span class="sd">     arms (list): collection of bandits to pull</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="o">&lt;&lt;</span><span class="n">constructor</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">best</span><span class="o">-</span><span class="n">arm</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">counts</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">rewards</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">select</span><span class="o">-</span><span class="n">arm</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">update</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">reset</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">call</span><span class="o">&gt;&gt;</span>
</pre></div>
</div>
<div id="outline-container-sec-4-1" class="outline-3">
<h3 id="sec-4-1">The Constructor</h3>
<div class="outline-text-3" id="text-4-1">
<p>
The constructor takes two arguments - <i>epsilon</i> and <i>arms</i>. The <i>arms</i> list should contain bandits that return a reward or penalty when pulled (called).
</p>

/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">arms</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">arms</span> <span class="o">=</span> <span class="n">arms</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_rewards</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">total_reward</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>

<div id="outline-container-sec-4-2" class="outline-3">
<h3 id="sec-4-2">Best Arm</h3>
<div class="outline-text-3" id="text-4-2">
<p>
The <code>best_arm</code> property returns the index of the arm that has the highest average reward so far. It returns the index instead of the arm itself because it's used to get the matching counts and rewards in the <code>update</code> method.
</p>

/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">best_arm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Index of the arm with the most reward&quot;&quot;&quot;</span>
    <span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">find_first</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div id="outline-container-sec-4-3" class="outline-3">
<h3 id="sec-4-3">Counts</h3>
<div class="outline-text-3" id="text-4-3">
<p>
The `counts` keeps track of the number of times each arm is pulled.
</p>

/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">counts</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;counts of times each arm is pulled</span>

<span class="sd">    Returns:</span>
<span class="sd">     numpy.array: array of counts</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">_counts</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">arms</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span>
</pre></div>
</div>
</div>
<div id="outline-container-sec-4-4" class="outline-3">
<h3 id="sec-4-4">Rewards</h3>
<div class="outline-text-3" id="text-4-4">
<p>
The <code>rewards</code> attributes holds the running average reward that each arm has returned.
</p>

/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;array of running average of rewards for each arms</span>

<span class="sd">    Returns:</span>
<span class="sd">     numpy.array: running averages</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rewards</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">_rewards</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">arms</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rewards</span>
</pre></div>
</div>
</div>
<div id="outline-container-sec-4-5" class="outline-3">
<h3 id="sec-4-5">Reset</h3>
<div class="outline-text-3" id="text-4-5">
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;sets the counts and rewards to None</span>

<span class="sd">    This lets you re-used the EpsilonGreedy without re-constructing</span>
<span class="sd">    the arms</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_rewards</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>

<div id="outline-container-sec-4-6" class="outline-3">
<h3 id="sec-4-6">Select Arm</h3>
<div class="outline-text-3" id="text-4-6">
<p>
The <i>select<sub>arm</sub></i> method will choose either the best arm or a random one based on a randomly drawn value and how it compares to epsilon.
</p>

/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">select_arm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;chooses the next arm to update</span>

<span class="sd">    Returns:</span>
<span class="sd">     int: index of the next arm to pull</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
	<span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">arms</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_arm</span>
</pre></div>
</div>
</div>

<div id="outline-container-sec-4-7" class="outline-3">
<h3 id="sec-4-7">Update</h3>
<div class="outline-text-3" id="text-4-7">
<p>
The update method pulls the arm whose index it is given and then updates the count and reward.
</p>

/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arm</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;pulls the arm and updates the value</span>

<span class="sd">    Args:</span>
<span class="sd">     arm (int): index of the arm to pull</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">counts</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">counts</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span>
    <span class="n">average_reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span>
    <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">arms</span><span class="p">[</span><span class="n">arm</span><span class="p">]()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span> <span class="o">=</span> <span class="p">(((</span><span class="n">count</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">count</span><span class="p">))</span> <span class="o">*</span> <span class="n">average_reward</span>
			<span class="o">+</span> <span class="p">(</span><span class="n">reward</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">count</span><span class="p">)))</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div id="outline-container-sec-4-8" class="outline-3">
<h3 id="sec-4-8">Call</h3>
<div class="outline-text-3" id="text-4-8">
<p>
The <i><span class="underline"><span class="underline">call</span></span></i> method will be the main update method that unifies the naming conventions found in the books.
</p>

/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;chooses an arm and updates the rewards&quot;&quot;&quot;</span>
    <span class="n">arm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_arm</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">arm</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
</div>

<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5">Epsilon Greedy Optimized</h2>
<div class="outline-text-2" id="text-5">
<p>
This is an attempt to get a version working that will work in numba.
</p>
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="o">&lt;&lt;</span><span class="n">optimized</span><span class="o">-</span><span class="n">imports</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">spec</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">find</span><span class="o">-</span><span class="n">first</span><span class="o">&gt;&gt;</span>
<span class="nd">@jitclass</span><span class="p">(</span><span class="n">spec</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">EpsilonGreedyOptimized</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The Epsilon Greedy Algorithm</span>

<span class="sd">    Args:</span>
<span class="sd">     epsilon (float): fraction of the time to explore</span>
<span class="sd">     arms (list): collection of probabilities for bandit arm</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="o">&lt;&lt;</span><span class="n">optimized</span><span class="o">-</span><span class="n">constructor</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">best</span><span class="o">-</span><span class="n">arm</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">select</span><span class="o">-</span><span class="n">arm</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">optimized</span><span class="o">-</span><span class="n">pull</span><span class="o">-</span><span class="n">arm</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">optimized</span><span class="o">-</span><span class="n">update</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">optimized</span><span class="o">-</span><span class="n">reset</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">call</span><span class="o">&gt;&gt;</span>
</pre></div>
</div>

<div id="outline-container-sec-5-1" class="outline-3">
<h3 id="sec-5-1">Optimized Imports</h3>
<div class="outline-text-3" id="text-5-1">
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="c1"># python</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">jit</span><span class="p">,</span>
    <span class="n">jitclass</span><span class="p">,</span>
    <span class="p">)</span>
<span class="kn">import</span> <span class="nn">numba</span>
<span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>
<div id="outline-container-sec-5-2" class="outline-3">
<h3 id="sec-5-2">The Spec</h3>
<div class="outline-text-3" id="text-5-2">
<p>
This is how you tell numba what attributes the class will have.
</p>
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="n">spec</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;epsilon&quot;</span><span class="p">,</span> <span class="n">numba</span><span class="o">.</span><span class="n">double</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;arms&quot;</span><span class="p">,</span> <span class="n">numba</span><span class="o">.</span><span class="n">double</span><span class="p">[:]),</span>
    <span class="p">(</span><span class="s2">&quot;counts&quot;</span><span class="p">,</span> <span class="n">numba</span><span class="o">.</span><span class="n">double</span><span class="p">[:]),</span>
    <span class="p">(</span><span class="s2">&quot;rewards&quot;</span><span class="p">,</span> <span class="n">numba</span><span class="o">.</span><span class="n">double</span><span class="p">[:]),</span>
    <span class="p">(</span><span class="s2">&quot;total_reward&quot;</span><span class="p">,</span> <span class="n">numba</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
<span class="p">]</span>
</pre></div>
</div>
</div>

<div id="outline-container-sec-5-3" class="outline-3">
<h3 id="sec-5-3">The Constructor</h3>
<div class="outline-text-3" id="text-5-3">
<p>
The constructor takes two arguments - <i>epsilon</i> and <i>arms</i>. The <i>arms</i> list should contain probabilities that a reward or penalty will be returned when pulled.
</p>

/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">arms</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">arms</span> <span class="o">=</span> <span class="n">arms</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">counts</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">arms</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">arms</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>

<div id="outline-container-sec-5-4" class="outline-3">
<h3 id="sec-5-4">Reset</h3>
<div class="outline-text-3" id="text-5-4">
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;sets the counts, rewards, total_reward to 0s</span>

<span class="sd">    This lets you re-used the EpsilonGreedy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">counts</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">arms</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">arms</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>

<div id="outline-container-sec-5-5" class="outline-3">
<h3 id="sec-5-5">Pull Arm</h3>
<div class="outline-text-3" id="text-5-5">
<p>
Since we can't give user-defined objects as attributes of the class, this version will be both algorithm and bandit.
</p>

/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">pull_arm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arm</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;gets the reward</span>

<span class="sd">    Args:</span>
<span class="sd">     arm (int): index for the arm-probability array</span>
<span class="sd">    Returns:</span>
<span class="sd">     int: reward or no reward</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">arms</span><span class="p">[</span><span class="n">arm</span><span class="p">]:</span>
	<span class="k">return</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="mi">1</span>
</pre></div>
</div>
</div>

<div id="outline-container-sec-5-6" class="outline-3">
<h3 id="sec-5-6">Update</h3>
<div class="outline-text-3" id="text-5-6">
<p>
The update method pulls the arm whose index it is given and then updates the count and reward. Here we're calling the <code>pull_arm</code> method instead of using a <code>BernoulliArm</code> so we can't re-use the original method.
</p>

/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
/home/hades/.virtualenvs/reinforcement_learning/bin/python: No module named virtualfish
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arm</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;pulls the arm and updates the value</span>

<span class="sd">    Args:</span>
<span class="sd">     arm (int): index of the arm to pull</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">counts</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">counts</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span>
    <span class="n">average_reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span>
    <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pull_arm</span><span class="p">(</span><span class="n">arm</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span> <span class="o">=</span> <span class="p">(((</span><span class="n">count</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">count</span><span class="p">))</span> <span class="o">*</span> <span class="n">average_reward</span>
			<span class="o">+</span> <span class="p">(</span><span class="n">reward</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">count</span><span class="p">)))</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
</div>

<div id="outline-container-sec-6" class="outline-2">
<h2 id="sec-6">References</h2>
<div class="outline-text-2" id="text-6">
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" name="fn.1" class="footnum" href="#fnr.1">1</a></sup> <p class="footpara">
Bandit Algorithms for Website Optimization by John Myles White. Copyright 2013 John Myles White, 978-1-449-34133-6
</p></div>


</div>
</div>
